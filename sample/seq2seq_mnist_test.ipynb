{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Example of seq2seq architecture to handwriting\n",
    "    - Train a seq2seq architecture over a sequence of digits generated by the MNIST dataset.\n",
    "    - Same model can be used to the general handwriting text recognition problem\n",
    "    - paper: Offline continuous handwriting recognition using sequence to sequence neural networks\n",
    "    - https://www.sciencedirect.com/science/article/pii/S0925231218301371 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "#Limit GPU cards\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "# Path to the data \n",
    "#data_path = '/tmp'\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "args = argparse.ArgumentParser()\n",
    "\n",
    "\n",
    "# Data loading params\n",
    "#args.add_argument(\"--data_path\", type=str, default='/tmp', help=\"data_path\")\n",
    "args.add_argument(\"--x_shape\", type=int, default=192, help=\"x_shape (default: 192)\")\n",
    "args.add_argument(\"--y_shape\", type=int, default=48, help=\"y_shape (default: 48)\")\n",
    "args.add_argument(\"--x_slide_size\", type=int, default=28, help=\"x_slide_size (default: 28)\")\n",
    "args.add_argument(\"--slides_stride\", type=int, default=2, help=\"slides_stride (default: 2)\")\n",
    "args.add_argument(\"--seq_decoder_len\", type=int, default=19, help=\"max_length of a word (default: 19)\")\n",
    "args.add_argument(\"--size\", type=int, default=10, help=\"size\")\n",
    "args.add_argument(\"--seq_length\", type=int, default=10, help=\"seq_length\")\n",
    "\n",
    "\n",
    "# Model Hyperparameters\n",
    "\n",
    "# Convolutional part parameters\n",
    "args.add_argument(\"--num_classes_char_model\", type=int, default=10, help=\"num_classes_char_model\")\n",
    "args.add_argument(\"--dense_size_char_model\", type=int, default=1024, help=\"dense size of the char model (default: 1024)\")\n",
    "\n",
    "# RNN parameters\n",
    "args.add_argument(\"--dim_lstm\", type=int, default=256, help=\"dim_lstm (default: 256)\")\n",
    "args.add_argument(\"--keep_prob\", type=float, default=0.5, help=\"keep_prob (default: 0.5)\")\n",
    "args.add_argument(\"--lambda_l2_reg\", type=float, default=0, help=\"lambda_l2_reg (default: 0)\")\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "args.add_argument(\"--experiment\", type=str, default='/tmp/mnist_sequence/exp01', help=\"Experiment absolute path\")\n",
    "args.add_argument(\"--load_model_name\", type=str, default='',\n",
    "                  help=\"If continue training, name of the model to load (default <BLANK> no continue training)\")\n",
    "args.add_argument(\"--learning_rate\", type=float, default=0.002, help=\"learning rate (default: 0.001)\")\n",
    "args.add_argument(\"--pct_lr_char_model\", type=float, default=0.1, help=\"Percent of learning rate applied to the char model part (default: 0.1)\")\n",
    "args.add_argument(\"--batch_size\", type=int, default=256, help=\"Batch Size (default: 256)\")\n",
    "args.add_argument(\"--exponential_decay_step\", type=int, default=100, help=\"exponential_decay_step (defaults 100)\")\n",
    "args.add_argument(\"--exponential_decay_rate\", type=float, default=0.95, help=\"exponential_decay_rate (default 0.95)\")\n",
    "args.add_argument(\"--min_steps\", type=int, default=10, help=\"min_steps (defaults 10 - min 10)\")\n",
    "args.add_argument(\"--max_steps\", type=int, default=1000, help=\"max_steps (defaults 1000 - min 1)\")\n",
    "\n",
    "\n",
    "\n",
    "FLAGS, unparsed = args.parse_known_args()\n",
    "print(\"\\nParameters:\", FLAGS)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "    - Build a generator of digits sequences of variable length from the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator parameters\n",
    "\n",
    "PAD_ID = 10\n",
    "GO_ID = 11\n",
    "EOL_ID = 12\n",
    "char_list = '0123456789'\n",
    "\n",
    "encode_dict={}\n",
    "decode_dict={}\n",
    "for i, s in enumerate(char_list):\n",
    "    encode_dict[s]=i\n",
    "    decode_dict[i]=s\n",
    "\n",
    "decode_dict[10]='-PAD'\n",
    "decode_dict[11]='GO'\n",
    "decode_dict[12]='-EOL'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_text(text_array, decoder_dict):\n",
    "    '''\n",
    "    Decode the target from numbers to words\n",
    "    '''\n",
    "    text = ''\n",
    "    eol_code = len(decoder_dict)-1\n",
    "    ind_eol = False\n",
    "    for c in text_array:\n",
    "        if ind_eol==False:\n",
    "            text += decoder_dict[c]\n",
    "        if c==eol_code:\n",
    "            ind_eol=True\n",
    "    return text\n",
    "#Test\n",
    "#print(decode_text(np.array([2, 1, 12, 11], dtype=np.uint8)), decode_dict) \n",
    "\n",
    "\n",
    "def data_generator(X, y, batch_size=256, size_word=3, size=3):    \n",
    "    ''' Generate sequences of MNIST digitis\n",
    "    Generates target as sequence and target_length\n",
    "        - size: size of the final image *28\n",
    "        - size_word: max number of digits in sequence\n",
    "    '''\n",
    "    img = np.zeros([batch_size, 28, 28*size])\n",
    "    img_l = np.zeros([batch_size])\n",
    "    target = np.zeros([batch_size,size_word])\n",
    "    target_l = np.zeros([batch_size])\n",
    "    \n",
    "    index_randomized = np.random.permutation(range(0, X.shape[0]))\n",
    "    index_ini = 0\n",
    "    for batch in range(batch_size):\n",
    "        n_digits = np.random.randint(1,size_word+1)    \n",
    "        img_l[batch] = n_digits * 28\n",
    "        target_l[batch] = n_digits\n",
    "        for i,index_pos in enumerate(range(index_ini, index_ini + n_digits)):\n",
    "            img[batch,:,i*28:(i+1)*28] = np.reshape(X[index_randomized[index_pos]],[28,28])\n",
    "            target[batch,i] = y[index_randomized[index_pos]]\n",
    "        index_ini += n_digits\n",
    "    return img, img_l, target, target_l\n",
    "\n",
    "\n",
    "def img_augmented(img1, angle=0.0):\n",
    "    ''' Data augmentation. Add some slant\n",
    "    '''\n",
    "    M = np.float32([[1, -angle, 0.5*img1.shape[0]*angle], [0, 1, 0]])\n",
    "    img2 = cv2.warpAffine(img1,M,(img1.shape[1], img1.shape[0]),flags=cv2.WARP_INVERSE_MAP|cv2.INTER_LINEAR)\n",
    "    return img2\n",
    "# plt.imshow(img_augmented(img[0], angle=-0.5))\n",
    "\n",
    "\n",
    "\n",
    "#Generate slides of the image\n",
    "def generate_slides(img_batch, img_len_batch, x_slide_size = 10, slides_stride = 2):\n",
    "    ''' Generate image slides to input the model\n",
    "    '''\n",
    "    #Normalize batch\n",
    "    #img_batch_normalized =  1 - (img_batch/255.)\n",
    "    img_batch_normalized = img_batch\n",
    "    \n",
    "    slides_batch = []\n",
    "    slides_len_batch = []\n",
    "    # Convert img_batch in a sequence of frames and calculate slides_len_batch\n",
    "    for n_img, img in enumerate(img_batch_normalized):\n",
    "        #Data augmentation\n",
    "        #img = img_augmented(img, random.random()-0.5)\n",
    "    \n",
    "        max_slides = int((img.shape[1] - x_slide_size)/float(slides_stride))\n",
    "        num_slides = max(2,min(max_slides, 1 + int((img_len_batch[n_img] - x_slide_size)/float(slides_stride))))\n",
    "        slides_img = np.zeros([img.shape[0], x_slide_size, max_slides])\n",
    "        \n",
    "        for num_slide in range(num_slides):\n",
    "            slides_img[:, :, num_slide] = img[:, num_slide*slides_stride : num_slide*slides_stride+x_slide_size]\n",
    "        slides_batch += [slides_img]\n",
    "\n",
    "        #Calculate slides_len_batch as the number of slides to get\n",
    "        slides_len_batch += [num_slides]\n",
    "\n",
    "    return np.array(slides_batch), np.array(slides_len_batch)\n",
    "\n",
    "\n",
    "\n",
    "def generate_target(y_ini, y_len, seq_length=3, num_classes=13):\n",
    "    ''' Generate target\n",
    "    '''\n",
    "    #Create vars: target, dec_inp and weigth\n",
    "    batch_size = y_ini.shape[0]\n",
    "    decoder_inputs = np.zeros([batch_size, seq_length+1, num_classes], dtype=np.float32)\n",
    "    weights = np.zeros([batch_size, seq_length+1], dtype=np.float32)\n",
    "    targets = np.zeros([batch_size, seq_length+1], dtype=np.uint16)\n",
    "    for batch_i in range(batch_size):\n",
    "        for char_pos in range(seq_length+1):\n",
    "            if char_pos == 0:\n",
    "                decoder_inputs[batch_i, char_pos, GO_ID] = 1\n",
    "                weights[batch_i, char_pos] = 1\n",
    "                targets[batch_i, char_pos] = int(y_ini[batch_i, char_pos])\n",
    "            elif char_pos < y_len[batch_i]:\n",
    "                decoder_inputs[batch_i, char_pos, int(y_ini[batch_i, char_pos-1])] = 1\n",
    "                weights[batch_i, char_pos] = 1\n",
    "                targets[batch_i, char_pos] = int(y_ini[batch_i, char_pos])\n",
    "            elif char_pos == y_len[batch_i]:\n",
    "                decoder_inputs[batch_i, char_pos, int(y_ini[batch_i, char_pos-1])] = 1\n",
    "                weights[batch_i, char_pos] = 1\n",
    "                targets[batch_i, char_pos] = EOL_ID\n",
    "            else:\n",
    "                decoder_inputs[batch_i, char_pos, PAD_ID] = 1\n",
    "                weights[batch_i, char_pos] = 0\n",
    "                targets[batch_i, char_pos] = PAD_ID\n",
    "\n",
    "    return decoder_inputs, targets, weights\n",
    "\n",
    "\n",
    "\n",
    "def batch_generator_epoch(X, y, batch_size=256, size_word=3, size=3, \n",
    "                          slides_stride=2, x_slide_size=10, num_classes=10+3, num_batches=100):\n",
    "    '''Generator for one epoch of data in batches\n",
    "    '''\n",
    "    for batch in range(num_batches):\n",
    "        img_b, img_b_l, target, target_l = data_generator(X, y, batch_size=batch_size,\n",
    "                                                      size_word=size_word, size=size) \n",
    "            \n",
    "        slides_batch, slides_len_batch = generate_slides(img_b, img_b_l, \n",
    "                                        x_slide_size = x_slide_size, slides_stride = slides_stride)\n",
    "    \n",
    "        decoder_inputs, targets, weights = generate_target(target, target_l, \n",
    "                                               seq_length=size, num_classes=num_classes)\n",
    "           \n",
    "        yield  slides_batch, slides_len_batch, decoder_inputs, targets, weights, img_b, target\n",
    "\n",
    "#Test\n",
    "'''\n",
    "seq = batch_generator_epoch(mnist.train.images, mnist.train.labels, batch_size = 2)    \n",
    "next_seq = seq.next()\n",
    "\n",
    "print('slides_batch: '    , next_seq[0].shape, next_seq[0][0])\n",
    "print('slides_len_batch: ', next_seq[1].shape, next_seq[1][0])\n",
    "print('decoder_inputs: '  , next_seq[2].shape, next_seq[2][0])\n",
    "print('targets: '         , next_seq[3].shape, next_seq[3][0])\n",
    "print('weights: '         , next_seq[4].shape, next_seq[4][0])\n",
    "print('X: '               , next_seq[5].shape, next_seq[5][0])\n",
    "print('y_ini: '           , next_seq[6].shape, next_seq[6][0])\n",
    "\n",
    "b = 0\n",
    "plt.imshow(next_seq[5][b])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sequence generator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "img, img_l, target, target_l = data_generator(x_train, y_train, batch_size=2)\n",
    "print(img_l, target, target_l)\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet_over_seq(img_seq, dropout_keep_prob):\n",
    "    ''' Convollutional part\n",
    "    Lenet model over a sequence of images\n",
    "    '''\n",
    "    #First convolution\n",
    "    W_conv_1 = tf.Variable(tf.truncated_normal([5, 5, 1, 20], stddev=0.1))\n",
    "    b_conv_1 = tf.Variable(tf.constant(0.1, shape=[20]))\n",
    "    conv1_out = [tf.nn.relu(tf.nn.conv2d(x_in, W_conv_1, strides=[1, 1, 1, 1], padding='SAME') + b_conv_1) for x_in in img_seq]\n",
    "    h_pool1 = [tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') for h_conv1 in conv1_out]\n",
    "\n",
    "    #Second convolution\n",
    "    W_conv_2 = tf.Variable(tf.truncated_normal([5, 5, 20, 50], stddev=0.1))\n",
    "    b_conv_2 = tf.Variable(tf.constant(0.1, shape=[50]))\n",
    "    conv2_out = [tf.nn.relu(tf.nn.conv2d(x_in, W_conv_2, strides=[1, 1, 1, 1], padding='SAME') + b_conv_2) for x_in in h_pool1]\n",
    "    h_pool2 = [tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') for h_conv2 in conv2_out]\n",
    "\n",
    "    #First dense layer\n",
    "    h_pool2_flat = [tf.reshape(hp, [-1, 7*7*50]) for hp in h_pool2]\n",
    "    \n",
    "    W_dense_1 = tf.Variable(tf.truncated_normal([7*7*50, FLAGS.dense_size_char_model], stddev=0.1))\n",
    "    b_dense_1 = tf.Variable(tf.constant(0.1, shape=[FLAGS.dense_size_char_model]))\n",
    "    dense_output_1 = [tf.nn.relu(tf.matmul(x_in, W_dense_1) + b_dense_1) for x_in in h_pool2_flat]\n",
    "    \n",
    "    #Dropout over \n",
    "    h_fc1_drop = [tf.nn.dropout(h_fc1, dropout_keep_prob) for h_fc1 in dense_output_1]\n",
    "\n",
    "    #Second dense layer\n",
    "    W_dense_2 = tf.Variable(tf.truncated_normal([FLAGS.dense_size_char_model, FLAGS.num_classes_char_model], stddev=0.1))\n",
    "    b_dense_2 = tf.Variable(tf.constant(0.1, shape=[FLAGS.num_classes_char_model]))\n",
    "    dense_output_2 = [tf.nn.relu(tf.matmul(x_in, W_dense_2) + b_dense_2) for x_in in h_fc1_drop]\n",
    "    \n",
    "    return dense_output_2\n",
    "\n",
    "\n",
    "def variable_summaries(var, name):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean/'   + name, mean)\n",
    "        tf.summary.scalar('sttdev/' + name, tf.sqrt(tf.reduce_mean(tf.square(var - mean))))\n",
    "        tf.summary.scalar('max/'    + name, tf.reduce_max(var))\n",
    "        tf.summary.scalar('min/'    + name, tf.reduce_min(var))\n",
    "        tf.summary.histogram(name, var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Create model\n",
    "\n",
    "# Model parameters\n",
    "\n",
    "# quitar?\n",
    "size = FLAGS.size\n",
    "\n",
    "#X length of slide\n",
    "x_slide_size = FLAGS.x_slide_size\n",
    "\n",
    "# X stride of slides\n",
    "slides_stride = FLAGS.slides_stride\n",
    "\n",
    "seq_length = FLAGS.seq_length\n",
    "\n",
    "dim_lstm = FLAGS.dim_lstm\n",
    "\n",
    "\n",
    "\n",
    "# Calculated\n",
    "x_size = seq_length*28\n",
    "\n",
    "# Num slides\n",
    "seq_input_len = int((x_size - x_slide_size)/float(slides_stride))\n",
    "\n",
    "vocab_size = len(char_list) + 3\n",
    "\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    #Placeholders\n",
    "    with tf.name_scope('inputs') as scope:\n",
    "        input_slides = tf.placeholder(tf.float32, shape=(None, 28, 28, seq_input_len), name='input_slides')\n",
    "        input_convolution = tf.split(input_slides, seq_input_len, axis=3)\n",
    "\n",
    "        input_slides_len = tf.placeholder(tf.int32, shape=(None), name='input_word_len')\n",
    "\n",
    "        input_word_chars = tf.placeholder(tf.float32, shape=(None, seq_length+1, vocab_size), name=\"input_word_chars\") \n",
    "        input_decoder = [tf.reshape(t, [-1, vocab_size]) for t in tf.split(input_word_chars, seq_length+1, axis=1)]\n",
    "\n",
    "        input_targets = tf.placeholder(tf.int32  , shape=[None, seq_length+1], name='input_targets')\n",
    "        input_weights = tf.placeholder(tf.float32, shape=[None, seq_length+1], name='input_weights')\n",
    "\n",
    "        weights = [tf.reshape(t, [-1]) for t in tf.split(input_weights, seq_length+1, axis=1)]\n",
    "        targets = [tf.reshape(t, [-1]) for t in tf.split(input_targets, seq_length+1, axis=1)]\n",
    "\n",
    "\n",
    "    ##Encoder\n",
    "    with tf.name_scope('encoder') as scope:\n",
    "        #Transform images to input to the LSTM\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        input_encoder = lenet_over_seq(input_convolution, keep_prob)    \n",
    "        input_encoder = tf.stack(input_encoder, axis=-1)\n",
    "        variable_summaries(input_encoder, 'input_encoder')\n",
    "\n",
    "        \n",
    "        # LSTM\n",
    "        cell_fw = tf.nn.rnn_cell.LSTMCell(dim_lstm,\n",
    "                      initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=123),\n",
    "                                               state_is_tuple=False)\n",
    "        cell_bw = tf.nn.rnn_cell.LSTMCell(dim_lstm,\n",
    "                      initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=113),\n",
    "                                               state_is_tuple=False)\n",
    "        \n",
    "        (enc_outputs_list, enc_state_list) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                          cell_fw, cell_bw, input_encoder, dtype=tf.float32,\n",
    "                          sequence_length=input_slides_len) \n",
    "        enc_outputs = tf.concat(enc_outputs_list, axis=2)\n",
    "                        \n",
    "        enc_state_b = enc_state_list[1] # state of the bw layer\n",
    "        attention_states = tf.concat(enc_outputs_list, axis=2)\n",
    "\n",
    "\n",
    "        \n",
    "    ##Decoder\n",
    "    with tf.name_scope('decoder') as scope:\n",
    "        W_decoder = tf.Variable(tf.truncated_normal([dim_lstm, vocab_size], stddev=0.1), name='W_decoder')\n",
    "        b_decoder = tf.Variable(tf.constant(0.1, shape=[vocab_size]), name='b_decoder')\n",
    "\n",
    "        cell_dec = tf.nn.rnn_cell.LSTMCell(dim_lstm,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=113),\n",
    "                                           state_is_tuple=False)\n",
    "        cell_dec = tf.nn.rnn_cell.DropoutWrapper(cell_dec, output_keep_prob=keep_prob)\n",
    "\n",
    "\n",
    "        def loop_function(prev, _):\n",
    "            # The next input are a softmax of the previous input\n",
    "            relu_prev = tf.nn.relu(tf.matmul(prev, W_decoder) + b_decoder)\n",
    "            return tf.nn.softmax(relu_prev)    \n",
    "\n",
    "        def decoder(feed_previous_bool):\n",
    "            loop_f = None if feed_previous_bool else loop_function\n",
    "            reuse = None if feed_previous_bool else True\n",
    "            with tf.variable_scope(\n",
    "                tf.get_variable_scope(), reuse=reuse) as scope:\n",
    "                dec_outputs, _ = tf.contrib.legacy_seq2seq.attention_decoder(input_decoder, enc_state_b,\n",
    "                                                                      attention_states, cell_dec, num_heads=1,\n",
    "                                                                      loop_function=loop_f)\n",
    "                            \n",
    "            return dec_outputs\n",
    "\n",
    "        # If feed_previous = True --> TEST: use the previous predicted output for the next output\n",
    "        # If feed_previous = False -->  TRAIN: use the real previous output to predict the next output\n",
    "        feed_previous = tf.placeholder(tf.bool)\n",
    "        dec_outputs = tf.cond(feed_previous, lambda: decoder(True), lambda: decoder(False))    \n",
    "        print('dec_outputs', dec_outputs)\n",
    "\n",
    "\n",
    "\n",
    "    with tf.name_scope('outputs') as scope:\n",
    "        dense_outputs = [tf.nn.relu(tf.matmul(dec_o, W_decoder) + b_decoder) for dec_o in dec_outputs]\n",
    "        variable_summaries(dense_outputs, 'dense_outputs')\n",
    "        \n",
    "        output_proba = tf.stack(dense_outputs, axis=-1, name='stack_output')\n",
    "                \n",
    "        #Prediction probs\n",
    "        output = tf.concat([tf.expand_dims(tf.nn.softmax(t),1) for t in dense_outputs], 1)\n",
    "        print('output', output)\n",
    "\n",
    "\n",
    "    #Loss\n",
    "    with tf.name_scope('loss') as scope:\n",
    "        loss = tf.contrib.legacy_seq2seq.sequence_loss(dense_outputs, targets, weights, name='seq2seq')\n",
    "        loss_summary = tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    #Trainer: different learning rate over the encoder part.\n",
    "    with tf.name_scope('trainer') as scope:\n",
    "        learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "        \n",
    "        #Lists of encoder vs other vars\n",
    "        encoder_vars=[]\n",
    "        other_vars = []\n",
    "        for t in tf.trainable_variables():\n",
    "            if t.name[:7] == 'encoder':\n",
    "                encoder_vars += [t] \n",
    "            else:\n",
    "                other_vars += [t] \n",
    "\n",
    "        \n",
    "        opt_encoder = tf.train.AdamOptimizer(learning_rate*0.1, beta1=0.9, beta2=0.999, epsilon=1e-08)\n",
    "        opt_other   = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-08)\n",
    "        \n",
    "        \n",
    "        grads = tf.gradients(loss, encoder_vars + other_vars)\n",
    "        grads_encoder = grads[:len(encoder_vars)]\n",
    "        grads_other   = grads[len(encoder_vars):]\n",
    "        \n",
    "        train_encoder = opt_encoder.apply_gradients(zip(grads_encoder, encoder_vars))\n",
    "        train_other   = opt_other.apply_gradients(zip(grads_other, other_vars))\n",
    "        train_op      = tf.group(train_encoder, train_other)\n",
    "        \n",
    "        \n",
    "        # If no different learning rates.\n",
    "        #optimizer = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-08)\n",
    "        #optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        #train_op = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "    # Saver \n",
    "    saver = tf.train.Saver(max_to_keep=0)\n",
    "\n",
    "    # Summaries\n",
    "    with tf.name_scope('summaries') as scope:\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "    # Add to collection \n",
    "    tf.add_to_collection('input_slides', input_slides)\n",
    "    tf.add_to_collection('input_slides_len', input_slides_len)\n",
    "    tf.add_to_collection('input_word_chars', input_word_chars)\n",
    "    tf.add_to_collection('input_targets', input_targets)\n",
    "    tf.add_to_collection('input_weights', input_weights)\n",
    "    tf.add_to_collection('output_proba', output_proba)\n",
    "    tf.add_to_collection('output', output)\n",
    "    tf.add_to_collection('keep_prob', keep_prob)\n",
    "    tf.add_to_collection('feed_previous', feed_previous)\n",
    "    tf.add_to_collection('loss', loss)\n",
    "    tf.add_to_collection('train_op', train_op)\n",
    "    tf.add_to_collection('merged', merged)\n",
    "\n",
    "print('MODEL CREATED!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_text(text_array, decoder_dict):\n",
    "    '''Decode the target from numbers to words\n",
    "    '''\n",
    "    text = ''\n",
    "    eol_code = len(decoder_dict)-1\n",
    "    ind_eol = False\n",
    "    for c in text_array:\n",
    "        if ind_eol==False:\n",
    "            text += decoder_dict[c]\n",
    "        if c==eol_code:\n",
    "            ind_eol=True\n",
    "    return text\n",
    "#Test\n",
    "#print(decode_text(np.array([2, 1, 12, 11], dtype=np.uint8)), decode_dict) \n",
    "\n",
    "\n",
    "def decode_response(response_array):\n",
    "    '''Decode response logits\n",
    "    '''\n",
    "    response_text = []\n",
    "    for i in range(response_array.shape[0]):\n",
    "        response_dec = [np.argmax(r) for r in response_array[i,:,:]]\n",
    "        response_text += [response_dec]\n",
    "    return response_text\n",
    "\n",
    "\n",
    "\n",
    "def train_batch(n_epochs, batch_size, lr=0.001, size_word=1, num_batches_epoch_trn=100, num_batches_epoch_tst=20):\n",
    "    '''Train the model several epochs\n",
    "    size_word: \n",
    "    '''\n",
    "    print('TRAIN STEP. Epochs: ', n_epochs, ' - size word: ', size_word)\n",
    "    step_summary = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        tic = time.clock()\n",
    "        loss_cumm = []\n",
    "        seq = batch_generator_epoch(x_train, y_train, batch_size=batch_size,\n",
    "                                    size_word=size_word,\n",
    "                                    size=size, \n",
    "                                    slides_stride=slides_stride,\n",
    "                                    x_slide_size=x_slide_size,\n",
    "                                    num_batches=num_batches_epoch_trn)\n",
    "        for s in seq:\n",
    "            feed_dict = {input_slides: s[0],\n",
    "                         input_slides_len: s[1],\n",
    "                         input_word_chars: s[2],\n",
    "                         input_targets: s[3],\n",
    "                         input_weights: s[4],\n",
    "                         keep_prob: 0.5,\n",
    "                         feed_previous: False, # False feed_previous in the trainig process.\n",
    "                         learning_rate: lr } \n",
    "            _, loss_t = sess.run([train_op, loss], feed_dict)\n",
    "            loss_cumm += [loss_t]\n",
    "            \n",
    "        # Sumaries train    \n",
    "        summary_str= sess.run(merged, feed_dict)\n",
    "        train_writer.add_summary(summary_str, step_summary)\n",
    "        \n",
    "        #Test\n",
    "        loss_cumm_tst = []\n",
    "        correct = 0\n",
    "        num_cases = 0\n",
    "        seq_tst = batch_generator_epoch(x_test, y_test, batch_size=batch_size,\n",
    "                                        size_word=size_word,\n",
    "                                        size=size, \n",
    "                                        slides_stride=slides_stride,\n",
    "                                        x_slide_size=x_slide_size,\n",
    "                                        num_batches=num_batches_epoch_tst)\n",
    "        for s_tst in seq_tst:\n",
    "            feed_dict_tst = {input_slides: s_tst[0],\n",
    "                         input_slides_len: s_tst[1],\n",
    "                         input_word_chars: s_tst[2],\n",
    "                         input_targets: s_tst[3],\n",
    "                         input_weights: s_tst[4],\n",
    "                         keep_prob: 1,\n",
    "                         feed_previous: True} # True feed_previous in the test process.\n",
    "            loss_tst, out_tst = sess.run([loss, output], feed_dict_tst)\n",
    "            loss_cumm_tst += [loss_tst]\n",
    "            \n",
    "            # Calculate the number of correct sequences (WER)\n",
    "            response_predict_text = decode_response(out_tst)\n",
    "            for resp in range(len(out_tst)):\n",
    "                num_cases += 1\n",
    "                if decode_text(s_tst[3][resp], decode_dict) == decode_text(response_predict_text[resp], decode_dict):\n",
    "                    correct += 1\n",
    "\n",
    "        # Sumaries test    \n",
    "        summary_str = sess.run(merged, feed_dict_tst)\n",
    "        test_writer.add_summary(summary_str, step_summary)\n",
    "        step_summary += 1\n",
    "           \n",
    "        print('Epoch: ',epoch, '- Loss trn: ', np.mean(loss_cumm), ' - Loss tst: ', np.mean(loss_cumm_tst))\n",
    "        print('Correct count: ', correct, ' - Correct percent (WER): ', float(correct)/float(num_cases))\n",
    "        print('Time', time.clock()-tic)\n",
    "        \n",
    "        # Print some results\n",
    "        print('Real vs pred examples:')\n",
    "        for resp in range(10):\n",
    "            print('     ', decode_text(s_tst[3][resp], decode_dict) ,\n",
    "                  ' vs ',  decode_text(response_predict_text[resp], decode_dict))\n",
    "            \n",
    "        \n",
    "    return loss_t, out_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(allow_growth = True)\n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    \n",
    "    # Merge all the summaries and write them out to /tmp/mnist_sequence\n",
    "    summaries_dir = FLAGS.experiment\n",
    "\n",
    "        \n",
    "    train_writer = tf.summary.FileWriter(os.path.join(summaries_dir, 'train'), sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(os.path.join(summaries_dir, 'test'))\n",
    "        \n",
    "    # Initialize vars    \n",
    "    tf.global_variables_initializer().run()\n",
    "    print('vars initialized!')\n",
    "\n",
    "    # Curriculum learning\n",
    "    # Increment the word size - decrement the learning rate\n",
    "    print('\\nCurriculum learning words of size 1:')\n",
    "    loss_t, out_tst = train_batch(5, FLAGS.batch_size, lr=FLAGS.learning_rate, size_word=1)\n",
    "\n",
    "    print('\\nCurriculum learning words of size <=2:')\n",
    "    loss_t, out_tst = train_batch(15, FLAGS.batch_size, lr=FLAGS.learning_rate*0.8, size_word=2)\n",
    "\n",
    "    #print('\\nCurriculum learning words of size <=3:')\n",
    "    #loss_t, out_tst = train_batch(15, FLAGS.batch_size, lr=FLAGS.learning_rate*0.6, size_word=3)\n",
    "\n",
    "\n",
    "    # Save final model\n",
    "    savefile = saver.save(sess, os.path.join(summaries_dir, 'final_model'))\n",
    "    print('Model saved in ', savefile)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf18]",
   "language": "python",
   "name": "conda-env-tf18-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
